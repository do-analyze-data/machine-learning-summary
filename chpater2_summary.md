># Part2_머신러닝의 주요 개념

 `모델` `손실 함수` `최적화` `모델 평가`
------------
### 2.1 모델: 문제를 바라보는 관점 ( 머신러닝의 시작점)
#### 2.1.1 모델이란
- 현재 상태를 어떠한 시각으로 바라보고 어떠한 기대를 하고있는가?
 - 머신러닝의 과정 (모델 정하기-> 모델 수식화 -> 모델 학습하기-> 모델 평가하기
   1. 모델 정하기(데이터의 생김새 가정)
   2. 모델의 학습 목표를 수식화 (--?)
   3. 실제 데이터로 모델을 학습(최적화)
   4. 평가

#### 2.1.2 모델 분류 (종류..?)
- 간단한 모델 (데이터의 구조가 간단) --> `선형모델` `선형 회귀`
  - 선형 모델 -> 미래 데이터가 이전에 정의된 데이터 포맷과 같은 패턴을 가질것으로 예측하는 기법
      - 장점
         * 데이터가 복잡하기 않고 간단하게 생겼을때
         * 결과를 이해하기 쉬움
         * 학습이 쉬움

      - 단점
         * 복잡한 관계 학습이 어려움
         * 가정 자체가 강력하여 모델의 표현 능력에 제한이 많음

  - 복잡한 모델 (모델의 유연성을 더 중요시함) --> `결정 트리`
   - 결정 트리 -> Building a decision tree that can classify all examples -- 복수의 비교식으로 정의

       (알고리즘)
            BuildTree (examples, properties)
            If all examples in C
               return a leaf node C
            Else-=
               root  select a property P
               for each value V of P
		         create branch
	  	         partitionV  examples that has value V
		         BuildTree (partitionV, properties)

	   - 장점
		  * 데이터가 어떻게 생겼을 것이라는 가정 자체가 별로 없습니다.
	   - 단점
		  * 결과를 이해하기 어려울 수도 있다.
		  * 학습이 복잡
		  * 한정된 데이터에서 만의 변화를 그대로 학습하므로 새로운 데이터에 대해 성능이 떨어질 수 있다.

 - 구조가 있는 모델 ( 단순 입출력의 상관관계와 데이터 구조 자체를 모델링) --> `순차 모델` `그래프 모델`
    즉 입,출력 요소가 서로 연관되어있는 모델
  - 순차 모델 --> 문서의 텍스트, 시관과 관계된 데이터 분석 EX) CRF,`RNN`
	* RNN )) 참고링크)) https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/ 에 잘 정리가 되어있습니다.

	       숨겨진 상태값: hidden layer 을 이용하여 순차적인 의존성을 표현한다.

 - 그래프 모델 --> 문서의 문법 구조를 직접 모델링하거나 이미지 픽셀사이의 관계를 네트워크로 보고 그래프로 표현하는 형태  ex) `MRF
    - 이미지의 경우 주로 픽셀은 근처 픽셀과 유사하거나 같은 값을 가지는 형태가 많기 때문에 사진의 특정 위치의 상태가 바로 근접합 위치의 상태들과 관련이 있다 가정합니다.
    - 그리고 실제로 관측된 값은 이러한 상태들로 인해 결정된다 가정하는 형태 입니다.

### 2.1.3 좋은 모델이란? "데이터의 패턴을 잘 학습한 모델" -> `편향-분산 트레이드 오프` `정규화`
#### 2.1.3.1 **편향-분산 트레이드 오프**
- 머신러닝 모델의 에러는 두가지로 분류할 수 있다->  `편향`과 `분산`
 - `편향`이란? 학습 데이터를 충분히 표현할 수 없기 때문에 발생하며 underfitting이 된 상태 ( 오렌지와 한라봉을 분류할 때 feature을 색으로만 잡았을 때)
 - `분산`이란? 학습 시 데이터에 너무 민감하게 반응하여 발생 overfitting이 된 상태
     예시)) ![image](https://user-images.githubusercontent.com/26568793/35679382-28db0476-079a-11e8-995c-fa4887cd6523.png)


- 모델의 성능을 극대화 하기 위한 방법  "편향이 너무 크지 않고, 너무 복잡하지 않아 분산이 작게 나와야한다"
 - 대표적인 예)) 부스팅, 랜덤 포레스트

#### 2.1.3.2 **정규화** : 정해진 모델이 필요 이상으로 복잡해지지 않도록 하는 트릭
  불필요한 노이즈의 학습을 줄이기 위한 방법
  1. 모델 변경
  2. 정규화: 모델에 들어 있는 인지에 제한을 두어 필요이상으로 복잡해지지 않게 한다. 즉, 추가적인 제약을 도입하여 필요없는 인자를 제거한다.

------------
### 2.2 `손실함수`: 모델의 수식화된 학습 목표
-> 모델이 실제로 데이터를 바르게 표현했는가, 예측이 정확한지 수학적으로 표현하는 방법
-  특징
 -  손실함수의 값이 작을 수록 정확한 모델이 됨 --> 에러가 작을 수록 좋은 것이니까
 -  같은 모델을 대상으로 해도 데이터의 특성에 따라 변형될 수 있음 ( 데이터를 보는 관점에 따라)

-  손실함수의 종류
  -  산술 손실함수 : 산술값을 예측할 때, 데이터에 대한 예측값과 실제 관측값을 비교
  -  확률 손실함수 : 항목이나 값에 대한 확률을 예측하는 경우
  -  랭킹 손실함수 : 추천 시스템에서 주로 사용, 모델로 순서를 결정할 때 주로 사용함
  -  모델 복잡도와 관련된 손실함수

#### 2.2.1 산술 손실함수
- 주로 **회귀모델**에 사용하는 것같음
- 예측값과 실제 관측값으 차이를 제곱으로 처리하는 법  -->  다층 퍼셉트론에서 오차 제곱합으로 비용함수를 구하는 것과 비슷..?
- 특징
  -  최적화가 쉬움
  -  손실값의 이해가 쉬움
- 절댓값을 사용하는 손실함수
  ----> 무슨말인지 모르겠음..하하

#### 2.2.2확률 손실함수  --> 읽어는 보았으나 정확한 이해를 통해 더 자세히 읽고 공부할 필요가 있음
- 이아이는 **특정항목을 고르는 분류 모델**에서 사용하기 적합함!
- 대표적 종류
  - MLE
  - Kullback Leibler divergence
  - Cross entropy (딥러닝에서 주로 사용)  --> soft max함수에 주로 활용된다 )) 참고 링크 https://ratsgo.github.io/deep%20learning/2017/09/24/loss/

#### 2.2.3 랭킹 손실함수
- 모델이 예측해낸 결과값의 순서가 맞는가?
- 추천 시스템, 랭킹 학습 분야에서 많이 사용
  - [pairwise zero-one loss]: 순서가 맞는지 확인하는 방식 (모든 쌍의 순서)
  - [edit distance]: 모델이 예측한 순서 목록에서 몇번의 편집 (맞바꿈 -- 원래 순서로 돌아가기 위해서)을 해야하는지 확인하는 방식

#### 2.2.4 모델 복잡도와 관련된 손실함수
- `정규화`효과를 내기 위해서 손실함수를 이용하여 제약 조건을 건다.
-  모델 복잡도를 위한 별도의 손실함수가 존재하는 것이 아닌 기존의 손실함수를 이용
- 수학적 학습(`최적화`)의 복잡함을 줄이기 위해서 `최적화`가 쉬운 손실함수(제약)을 정한다.
------------
### 2.3 `최적화`: 손실함수를 이용하여 실제로 학습을 하는 방법
- `최적화`란? 결괏값을 최소화하는 모델의 인자를 찾는 것 (가중치라고도 하나...?)
- 종류
  - Gradient descent
  - newton/quasi-netwon method
  - stochastic grdient descent
  - backpropagation
  - 최신 최적화 방법

#### 2.3.1 Grdient descent (경사 하강법) --> 인공지능 학습 노트를 보고 다시 공부 후 업데이트 할 예정
* 참고)) https://www.youtube.com/watch?v=GmtqOlPYB84
- 왜 경사하강법을 사용하는가?
  - 하나의 임의의 지점에서 시작하여 경사를 따라 내려갈 수 없을 때까지 반복적으로 내려간 후 최적화 값까지 도달하는 것을 의미
![image](https://user-images.githubusercontent.com/26568793/35721340-cc4ba47c-0834-11e8-8e83-713d473c472a.png)
  - 초기 임의로 설정한 wieght에서 경사를 하강 시켜가며 가장 최소의 값을 찾는 것이다. [기울기(여기서 기울기가 오차이기 때문에)를 줄인다.]
    따라서 기울기를 알기 위해서는 미분이 필요하기 때문에 값을 제곱하고 그이ㅡ 기울기를 구함.
    또한 미분을해서 0이 나오는 비용함수 w를 구하는 것이다. 그것을 통해 학습을 하며 최적화 값을 찾아 나감.

#### 2.3.2 newton/quasi-netwon method
- newton 학습 방법이란?
   - 임의의 학습률을 사용하는 것이 아닌 1차, 2차 미분값을 이용하여 가중치 값의 업데이트를 진행함.
   - 단순 경사 하강법보다 훨씬 빠른 속도로 최적화 속도를 보이나 2차 미분이 어렵기 때문에 한계가 존재함.
- 대표적 방법
   - BFGS
   - LBFGS
    --> 데이터가 많지 않은 경우 뛰어난 성능을 보임

#### 2.3.3. 확률적 경사하강법 (SGD)
- 뉴턴/준 뉴턴 하강법을 이용했을 시 최근 데이터가 많아짐에 따라 학습시간이 길어진다는 단점이 존재함
  이를 위해 손실함수와 1차 미분값을 전체 데이터에 계산하는 것이 아닌 일부 데이터만 이용하여 근사적으로 계산하는
  확률적 경사하강법을 사용함
- SGD에서 이 처럼 n개의 데이터를 뽑아 방법
  - 데이터를 처음부터 끝까지 업데이트
  - 미니 배치 SGD

#### 2.3.4 오류 역전파 (backpropagation)
 --> 인공지능 학습 노트 공부 후 다시 업데이트 예정
![image](https://user-images.githubusercontent.com/26568793/35721395-2319cca2-0835-11e8-98ab-fc43aeb34568.png)
- 보통 손실함수가 층층이 쌓인 구조
- 은닉층의 학습을 위해 출력층에서 발생한 오류를 이용하여 은닉층 오류를 계산하고
   다시 이 값을 입력층으로 역전파시켜 출력층의 오차가 원하는 수준이 될 때 까지 반복하는 과정
- 초기화 --> 전방향 진행 --> 오류 역전파에 의한 수정 --> 제어

#### 2.3.5 최신 최적화 방법
- Adam
- AdaGrad
------------
### 2.4 모델 평가: 실제 활용에서 성능을 평가하는 방법





























