># Part2_머신러닝의 주요 개념

 `모델` `손실 함수` `최적화` `모델 평가`
------------
### 2.1 모델: 문제를 바라보는 관점 ( 머신러닝의 시작점)
#### 2.1.1 모델이란
- 현재 상태를 어떠한 시각으로 바라보고 어떠한 기대를 하고있는가?
 - 머신러닝의 과정 (모델 정하기-> 모델 수식화 -> 모델 학습하기-> 모델 평가하기
   1. 모델 정하기(데이터의 생김새 가정)
   2. 모델의 학습 목표를 수식화 (--?)
   3. 실제 데이터로 모델을 학습(최적화)
   4. 평가

#### 2.1.2 모델 분류 (종류..?)
- 간단한 모델 (데이터의 구조가 간단) --> `선형모델` `선형 회귀`
  - 선형 모델 -> 미래 데이터가 이전에 정의된 데이터 포맷과 같은 패턴을 가질것으로 예측하는 기법
      - 장점
         * 데이터가 복잡하기 않고 간단하게 생겼을때
         * 결과를 이해하기 쉬움
         * 학습이 쉬움

      - 단점
         * 복잡한 관계 학습이 어려움
         * 가정 자체가 강력하여 모델의 표현 능력에 제한이 많음

  - 복잡한 모델 (모델의 유연성을 더 중요시함) --> `결정 트리`
   - 결정 트리 -> Building a decision tree that can classify all examples -- 복수의 비교식으로 정의

       (알고리즘)
            BuildTree (examples, properties)
            If all examples in C
               return a leaf node C
            Else-=
               root  select a property P
               for each value V of P
		         create branch
	  	         partitionV  examples that has value V
		         BuildTree (partitionV, properties)

	   - 장점
		  * 데이터가 어떻게 생겼을 것이라는 가정 자체가 별로 없습니다.
	   - 단점
		  * 결과를 이해하기 어려울 수도 있다.
		  * 학습이 복잡
		  * 한정된 데이터에서 만의 변화를 그대로 학습하므로 새로운 데이터에 대해 성능이 떨어질 수 있다.

 - 구조가 있는 모델 ( 단순 입출력의 상관관계와 데이터 구조 자체를 모델링) --> `순차 모델` `그래프 모델`
    즉 입,출력 요소가 서로 연관되어있는 모델
  - 순차 모델 --> 문서의 텍스트, 시관과 관계된 데이터 분석 EX) CRF,`RNN`
	* RNN )) 참고링크)) https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/ 에 잘 정리가 되어있습니다.

	       숨겨진 상태값: hidden layer 을 이용하여 순차적인 의존성을 표현한다.

 - 그래프 모델 --> 문서의 문법 구조를 직접 모델링하거나 이미지 픽셀사이의 관계를 네트워크로 보고 그래프로 표현하는 형태  ex) `MRF
    - 이미지의 경우 주로 픽셀은 근처 픽셀과 유사하거나 같은 값을 가지는 형태가 많기 때문에 사진의 특정 위치의 상태가 바로 근접합 위치의 상태들과 관련이 있다 가정합니다.
    - 그리고 실제로 관측된 값은 이러한 상태들로 인해 결정된다 가정하는 형태 입니다.

### 2.1.3 좋은 모델이란? "데이터의 패턴을 잘 학습한 모델" -> `편향-분산 트레이드 오프` `정규화`
#### 2.1.3.1 **편향-분산 트레이드 오프**
- 머신러닝 모델의 에러는 두가지로 분류할 수 있다->  `편향`과 `분산`
 - `편향`이란? 학습 데이터를 충분히 표현할 수 없기 때문에 발생하며 underfitting이 된 상태 ( 오렌지와 한라봉을 분류할 때 feature을 색으로만 잡았을 때)
 - `분산`이란? 학습 시 데이터에 너무 민감하게 반응하여 발생 overfitting이 된 상태
     예시)) ![image](https://user-images.githubusercontent.com/26568793/35679382-28db0476-079a-11e8-995c-fa4887cd6523.png)


- 모델의 성능을 극대화 하기 위한 방법  "편향이 너무 크지 않고, 너무 복잡하지 않아 분산이 작게 나와야한다"
 - 대표적인 예)) 부스팅, 랜덤 포레스트

#### 2.1.3.2 **정규화** : 정해진 모델이 필요 이상으로 복잡해지지 않도록 하는 트릭
  불필요한 노이즈의 학습을 줄이기 위한 방법
  1. 모델 변경
  2. 정규화: 모델에 들어 있는 인지에 제한을 두어 필요이상으로 복잡해지지 않게 한다. 즉, 추가적인 제약을 도입하여 필요없는 인자를 제거한다.

###2.2 손실함수: 모델의 수식화된 학습 목표























